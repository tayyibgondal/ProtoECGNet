{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "517c6ae8-d44f-41c2-b6ed-624e807973b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available\n",
      "Device count: 8\n",
      "Device name: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available\")\n",
    "    print(f\"Device count: {torch.cuda.device_count()}\")\n",
    "    print(f\"Device name: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "905a34cf-3ca1-4a0d-99d0-bbe2b7d9d76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.4.0\n",
      "CUDA version: 12.1\n",
      "CUDA is available\n",
      "Device 0: Tesla V100-SXM2-32GB\n",
      "Device 1: Tesla V100-SXM2-32GB\n",
      "Device 2: Tesla V100-SXM2-32GB\n",
      "Device 3: Tesla V100-SXM2-32GB\n",
      "Device 4: Tesla V100-SXM2-32GB\n",
      "Device 5: Tesla V100-SXM2-32GB\n",
      "Device 6: Tesla V100-SXM2-32GB\n",
      "Device 7: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"Device {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3d4c81c-d4a9-4260-b676-af1d9011106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0a32e45-2df5-4fda-add7-8946046e9e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ecg_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>filename_lr</th>\n",
       "      <th>filename_hr</th>\n",
       "      <th>Normal_ECG</th>\n",
       "      <th>ecg_lr_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>109</td>\n",
       "      <td>21312.0</td>\n",
       "      <td>records100/00000/00109_lr</td>\n",
       "      <td>records500/00000/00109_hr</td>\n",
       "      <td>True</td>\n",
       "      <td>00109_lr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>19314</td>\n",
       "      <td>19314</td>\n",
       "      <td>19353</td>\n",
       "      <td>19389.0</td>\n",
       "      <td>records100/19000/19353_lr</td>\n",
       "      <td>records500/19000/19353_hr</td>\n",
       "      <td>False</td>\n",
       "      <td>19353_lr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>12707</td>\n",
       "      <td>12707</td>\n",
       "      <td>12739</td>\n",
       "      <td>16579.0</td>\n",
       "      <td>records100/12000/12739_lr</td>\n",
       "      <td>records500/12000/12739_hr</td>\n",
       "      <td>True</td>\n",
       "      <td>12739_lr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>18414</td>\n",
       "      <td>18414</td>\n",
       "      <td>18453</td>\n",
       "      <td>21182.0</td>\n",
       "      <td>records100/18000/18453_lr</td>\n",
       "      <td>records500/18000/18453_hr</td>\n",
       "      <td>False</td>\n",
       "      <td>18453_lr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10879</td>\n",
       "      <td>10879</td>\n",
       "      <td>10906</td>\n",
       "      <td>14854.0</td>\n",
       "      <td>records100/10000/10906_lr</td>\n",
       "      <td>records500/10000/10906_hr</td>\n",
       "      <td>True</td>\n",
       "      <td>10906_lr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  index  Unnamed: 0  ecg_id  patient_id  \\\n",
       "0             0    108         108     109     21312.0   \n",
       "1             1  19314       19314   19353     19389.0   \n",
       "2             2  12707       12707   12739     16579.0   \n",
       "3             3  18414       18414   18453     21182.0   \n",
       "4             4  10879       10879   10906     14854.0   \n",
       "\n",
       "                 filename_lr                filename_hr  Normal_ECG  \\\n",
       "0  records100/00000/00109_lr  records500/00000/00109_hr        True   \n",
       "1  records100/19000/19353_lr  records500/19000/19353_hr       False   \n",
       "2  records100/12000/12739_lr  records500/12000/12739_hr        True   \n",
       "3  records100/18000/18453_lr  records500/18000/18453_hr       False   \n",
       "4  records100/10000/10906_lr  records500/10000/10906_hr        True   \n",
       "\n",
       "  ecg_lr_path  \n",
       "0    00109_lr  \n",
       "1    19353_lr  \n",
       "2    12739_lr  \n",
       "3    18453_lr  \n",
       "4    10906_lr  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to the CSV file\n",
    "csv_file_for_labels = '../../../data/padmalab_external/special_project/physionet.org/files/ptb-xl/1.0.3/ptbxl_train_label_df.csv'\n",
    "# Path to the image directory\n",
    "data_dir = '../../../data/padmalab_external/special_project/physionet.org/files/ptb-xl/1.0.3/records100_ground_truth'\n",
    "\n",
    "# Load the CSV file\n",
    "label_df = pd.read_csv(csv_file_for_labels)\n",
    "train_df = label_df.sample(frac = 0.8)\n",
    "test_df = label_df.drop(train_df.index)\n",
    "label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6ff91f6-7814-4170-ab6d-591dbe36f540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12556"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e0e0b62-4878-456d-9bae-aad38d17dec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3139"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd67f771-e507-43f7-be06-be3058178c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "img_size = 224  # or whatever size you want\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73976827-c005-4f06-8310-cd084b4d545f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "class ECGImageDataset(Dataset):\n",
    "    def __init__(self, label_df, image_dir, transform=None):\n",
    "        self.label_df = label_df\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = self._get_image_paths()\n",
    "\n",
    "    def _get_image_paths(self):\n",
    "        image_paths = []\n",
    "        for root, _, files in os.walk(self.image_dir):\n",
    "            for file in files:\n",
    "                if file.endswith('.png'):\n",
    "                    image_paths.append(os.path.join(root, file))\n",
    "        return image_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.label_df.iloc[idx]['ecg_lr_path'] + '-0.png'\n",
    "        matching_paths = [path for path in self.image_paths if img_name in path]\n",
    "        \n",
    "        # Use the first match if it exists\n",
    "        img_path = matching_paths[0] if matching_paths else None\n",
    "        \n",
    "        while img_path is None:\n",
    "            idx += 1\n",
    "            img_name = self.label_df.iloc[idx]['ecg_lr_path'] + '-0.png'\n",
    "            matching_paths = [path for path in self.image_paths if img_name in path]\n",
    "            # Use the first match if it exists\n",
    "            img_path = matching_paths[0] if matching_paths else None\n",
    "\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.label_df.iloc[idx]['Normal_ECG']\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "train_dataset = ECGImageDataset(train_df, data_dir, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=False)\n",
    "\n",
    "test_dataset = ECGImageDataset(test_df, data_dir, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=False)\n",
    "\n",
    "# Example of iterating through the dataloader\n",
    "for images, labels in train_loader:\n",
    "    print(images.shape, labels.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ee9d2f4-d942-44eb-bb3c-d0b547d949c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "        1, 1, 1, 0, 1, 0, 0, 0], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print(labels.int())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cc8f134-6d71-404d-bb6a-739bcd2e7f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "# import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import argparse\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from helpers import makedir\n",
    "import model\n",
    "import push\n",
    "import train_and_test as tnt\n",
    "import save\n",
    "from log import create_logger\n",
    "from preprocess import mean, std, preprocess_input_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14e96f24-0c07-4b64-bee2-907fff09c21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "from helpers import list_of_distances, make_one_hot\n",
    "\n",
    "import time\n",
    "import torch\n",
    "from sklearn.metrics import f1_score, roc_auc_score,accuracy_score\n",
    "\n",
    "def _train_or_test(model, dataloader, optimizer=None, class_specific=True, use_l1_mask=True,\n",
    "                   coefs=None, log=print):\n",
    "    is_train = optimizer is not None\n",
    "    start = time.time()\n",
    "    n_examples = 0\n",
    "    n_correct = 0\n",
    "    n_batches = 0\n",
    "    total_cross_entropy = 0\n",
    "    total_cluster_cost = 0\n",
    "    total_separation_cost = 0\n",
    "    total_avg_separation_cost = 0\n",
    "\n",
    "    all_labels = []\n",
    "    all_scores = []\n",
    "\n",
    "    for i, (image, label) in enumerate(dataloader):\n",
    "        if i > 3:\n",
    "            continue\n",
    "        input = image.cuda()\n",
    "        target = label.cuda()\n",
    "\n",
    "        grad_req = torch.enable_grad() if is_train else torch.no_grad()\n",
    "        with grad_req:\n",
    "            output, min_distances = model(input)\n",
    "\n",
    "            cross_entropy = torch.nn.functional.cross_entropy(output, target)\n",
    "\n",
    "            if class_specific:\n",
    "                max_dist = (model.module.prototype_shape[1]\n",
    "                            * model.module.prototype_shape[2]\n",
    "                            * model.module.prototype_shape[3])\n",
    "\n",
    "                prototypes_of_correct_class = torch.t(model.module.prototype_class_identity[:, label]).cuda()\n",
    "                inverted_distances, _ = torch.max((max_dist - min_distances) * prototypes_of_correct_class, dim=1)\n",
    "                cluster_cost = torch.mean(max_dist - inverted_distances)\n",
    "\n",
    "                prototypes_of_wrong_class = 1 - prototypes_of_correct_class\n",
    "                inverted_distances_to_nontarget_prototypes, _ = \\\n",
    "                    torch.max((max_dist - min_distances) * prototypes_of_wrong_class, dim=1)\n",
    "                separation_cost = torch.mean(max_dist - inverted_distances_to_nontarget_prototypes)\n",
    "\n",
    "                avg_separation_cost = \\\n",
    "                    torch.sum(min_distances * prototypes_of_wrong_class, dim=1) / torch.sum(prototypes_of_wrong_class, dim=1)\n",
    "                avg_separation_cost = torch.mean(avg_separation_cost)\n",
    "                \n",
    "                if use_l1_mask:\n",
    "                    l1_mask = 1 - torch.t(model.module.prototype_class_identity).cuda()\n",
    "                    l1 = (model.module.last_layer.weight * l1_mask).norm(p=1)\n",
    "                else:\n",
    "                    l1 = model.module.last_layer.weight.norm(p=1)\n",
    "\n",
    "            else:\n",
    "                min_distance, _ = torch.min(min_distances, dim=1)\n",
    "                cluster_cost = torch.mean(min_distance)\n",
    "                l1 = model.module.last_layer.weight.norm(p=1)\n",
    "\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            n_examples += target.size(0)\n",
    "            n_batches += 1\n",
    "            n_correct += (predicted == target).sum().item()\n",
    "\n",
    "            total_cross_entropy += cross_entropy.item()\n",
    "            total_cluster_cost += cluster_cost.item()\n",
    "            total_separation_cost += separation_cost.item()\n",
    "            total_avg_separation_cost += avg_separation_cost.item()\n",
    "\n",
    "            # Append to all_labels and all_scores\n",
    "            all_labels.extend(target.cpu().numpy())\n",
    "            all_scores.extend(output.softmax(dim=1).detach().cpu().numpy())\n",
    "\n",
    "        if is_train:\n",
    "            if class_specific:\n",
    "                if coefs is not None:\n",
    "                    loss = (coefs['crs_ent'] * cross_entropy\n",
    "                          + coefs['clst'] * cluster_cost\n",
    "                          + coefs['sep'] * separation_cost\n",
    "                          + coefs['l1'] * l1)\n",
    "                else:\n",
    "                    loss = cross_entropy + 0.8 * cluster_cost - 0.08 * separation_cost + 1e-4 * l1\n",
    "            else:\n",
    "                if coefs is not None:\n",
    "                    loss = (coefs['crs_ent'] * cross_entropy\n",
    "                          + coefs['clst'] * cluster_cost\n",
    "                          + coefs['l1'] * l1)\n",
    "                else:\n",
    "                    loss = cross_entropy + 0.8 * cluster_cost + 1e-4 * l1\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        del input\n",
    "        del target\n",
    "        del output\n",
    "        del predicted\n",
    "        del min_distances\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    log('\\ttime: \\t{0}'.format(end - start))\n",
    "    log('\\tcross ent: \\t{0}'.format(total_cross_entropy / n_batches))\n",
    "    log('\\tcluster: \\t{0}'.format(total_cluster_cost / n_batches))\n",
    "    if class_specific:\n",
    "        log('\\tseparation:\\t{0}'.format(total_separation_cost / n_batches))\n",
    "        log('\\tavg separation:\\t{0}'.format(total_avg_separation_cost / n_batches))\n",
    "    log('\\taccu: \\t\\t{0}%'.format(n_correct / n_examples * 100))\n",
    "    log('\\tl1: \\t\\t{0}'.format(model.module.last_layer.weight.norm(p=1).item()))\n",
    "    p = model.module.prototype_vectors.view(model.module.num_prototypes, -1).cpu()\n",
    "    with torch.no_grad():\n",
    "        p_avg_pair_dist = torch.mean(list_of_distances(p, p))\n",
    "    log('\\tp dist pair: \\t{0}'.format(p_avg_pair_dist.item()))\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, [score.argmax() for score in all_scores])\n",
    "    f1 = f1_score(all_labels, [score.argmax() for score in all_scores], average='weighted')\n",
    "    auroc = roc_auc_score(all_labels, all_scores[:, 0], multi_class='ovr', average='weighted')\n",
    "\n",
    "    log(f'\\tAccuracy: {accuracy * 100:.2f}%')\n",
    "    log(f'\\tF1 Score: {f1:.4f}')\n",
    "    log(f'\\tAUROC: {auroc:.4f}')\n",
    "\n",
    "    return n_correct / n_examples\n",
    "\n",
    "\n",
    "def train(model, dataloader, optimizer, class_specific=False, coefs=None, log=print):\n",
    "    assert(optimizer is not None)\n",
    "    \n",
    "    log('\\ttrain')\n",
    "    model.train()\n",
    "    return _train_or_test(model=model, dataloader=dataloader, optimizer=optimizer,\n",
    "                          class_specific=class_specific, coefs=coefs, log=log)\n",
    "\n",
    "\n",
    "def test(model, dataloader, class_specific=False, log=print):\n",
    "    log('\\ttest')\n",
    "    model.eval()\n",
    "    return _train_or_test(model=model, dataloader=dataloader, optimizer=None,\n",
    "                          class_specific=class_specific, log=log)\n",
    "\n",
    "\n",
    "def last_only(model, log=print):\n",
    "    for p in model.module.features.parameters():\n",
    "        p.requires_grad = False\n",
    "    for p in model.module.add_on_layers.parameters():\n",
    "        p.requires_grad = False\n",
    "    model.module.prototype_vectors.requires_grad = False\n",
    "    for p in model.module.last_layer.parameters():\n",
    "        p.requires_grad = True\n",
    "    \n",
    "    log('\\tlast layer')\n",
    "\n",
    "\n",
    "def warm_only(model, log=print):\n",
    "    for p in model.module.features.parameters():\n",
    "        p.requires_grad = False\n",
    "    for p in model.module.add_on_layers.parameters():\n",
    "        p.requires_grad = True\n",
    "    model.module.prototype_vectors.requires_grad = True\n",
    "    for p in model.module.last_layer.parameters():\n",
    "        p.requires_grad = True\n",
    "    \n",
    "    log('\\twarm')\n",
    "\n",
    "\n",
    "def joint(model, log=print):\n",
    "    for p in model.module.features.parameters():\n",
    "        p.requires_grad = True\n",
    "    for p in model.module.add_on_layers.parameters():\n",
    "        p.requires_grad = True\n",
    "    model.module.prototype_vectors.requires_grad = True\n",
    "    for p in model.module.last_layer.parameters():\n",
    "        p.requires_grad = True\n",
    "    \n",
    "    log('\\tjoint')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b83813-13be-4a62-a35e-c8eee9d6ff44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# book keeping namings and code\n",
    "from settings import base_architecture, img_size, prototype_shape, num_classes, \\\n",
    "                     prototype_activation_function, add_on_layers_type, experiment_run\n",
    "\n",
    "base_architecture_type = re.match('^[a-z]*', base_architecture).group(0)\n",
    "\n",
    "model_dir = './saved_models/' + base_architecture + '/' + experiment_run + '/'\n",
    "makedir(model_dir)\n",
    "# shutil.copy(src=os.path.join(os.getcwd(), __file__), dst=model_dir)\n",
    "shutil.copy(src=os.path.join(os.getcwd(), 'settings.py'), dst=model_dir)\n",
    "shutil.copy(src=os.path.join(os.getcwd(), base_architecture_type + '_features.py'), dst=model_dir)\n",
    "shutil.copy(src=os.path.join(os.getcwd(), 'model.py'), dst=model_dir)\n",
    "shutil.copy(src=os.path.join(os.getcwd(), 'train_and_test.py'), dst=model_dir)\n",
    "\n",
    "log, logclose = create_logger(log_filename=os.path.join(model_dir, 'train.log'))\n",
    "img_dir = os.path.join(model_dir, 'img')\n",
    "makedir(img_dir)\n",
    "weight_matrix_filename = 'outputL_weights'\n",
    "prototype_img_filename_prefix = 'prototype-img'\n",
    "prototype_self_act_filename_prefix = 'prototype-self-act'\n",
    "proto_bound_boxes_filename_prefix = 'bb'\n",
    "\n",
    "# load the data\n",
    "from settings import train_dir, test_dir, train_push_dir, \\\n",
    "                     train_batch_size, test_batch_size, train_push_batch_size\n",
    "# ---------------------------------------------------------------\n",
    "# Updated data loader code\n",
    "from settings import data_dir, csv_file_for_labels\n",
    "from dataset_class import ECGImageDataset\n",
    "\n",
    "# Define transformations\n",
    "img_size = 224  # or whatever size you want\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "# Load the CSV file\n",
    "label_df = pd.read_csv(csv_file_for_labels)\n",
    "\n",
    "train_dataset = ECGImageDataset(label_df, data_dir, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True, num_workers=4, pin_memory=False)\n",
    "\n",
    "# we should look into distributed sampler more carefully at torch.utils.data.distributed.DistributedSampler(train_dataset)\n",
    "log('training set size: {0}'.format(len(train_loader.dataset)))\n",
    "# log('push set size: {0}'.format(len(train_push_loader.dataset)))\n",
    "# log('test set size: {0}'.format(len(test_loader.dataset)))\n",
    "log('batch size: {0}'.format(train_batch_size))\n",
    "\n",
    "# construct the model\n",
    "base_architecture = 'resnet18'\n",
    "ppnet = model.construct_PPNet(base_architecture=base_architecture,\n",
    "                              pretrained=True, img_size=img_size,\n",
    "                              prototype_shape=prototype_shape,\n",
    "                              num_classes=num_classes,\n",
    "                              prototype_activation_function=prototype_activation_function,\n",
    "                              add_on_layers_type=add_on_layers_type)\n",
    "#if prototype_activation_function == 'linear':\n",
    "#    ppnet.set_last_layer_incorrect_connection(incorrect_strength=0)\n",
    "ppnet = ppnet.to('cuda')\n",
    "ppnet_multi = torch.nn.DataParallel(ppnet)\n",
    "class_specific = True\n",
    "\n",
    "# define optimizer\n",
    "from settings import joint_optimizer_lrs, joint_lr_step_size\n",
    "joint_optimizer_specs = \\\n",
    "[{'params': ppnet.features.parameters(), 'lr': joint_optimizer_lrs['features'], 'weight_decay': 1e-3}, # bias are now also being regularized\n",
    " {'params': ppnet.add_on_layers.parameters(), 'lr': joint_optimizer_lrs['add_on_layers'], 'weight_decay': 1e-3},\n",
    " {'params': ppnet.prototype_vectors, 'lr': joint_optimizer_lrs['prototype_vectors']},\n",
    "]\n",
    "joint_optimizer = torch.optim.Adam(joint_optimizer_specs)\n",
    "joint_lr_scheduler = torch.optim.lr_scheduler.StepLR(joint_optimizer, step_size=joint_lr_step_size, gamma=0.1)\n",
    "\n",
    "from settings import warm_optimizer_lrs\n",
    "warm_optimizer_specs = \\\n",
    "[{'params': ppnet.add_on_layers.parameters(), 'lr': warm_optimizer_lrs['add_on_layers'], 'weight_decay': 1e-3},\n",
    " {'params': ppnet.prototype_vectors, 'lr': warm_optimizer_lrs['prototype_vectors']},\n",
    "]\n",
    "warm_optimizer = torch.optim.Adam(warm_optimizer_specs)\n",
    "\n",
    "from settings import last_layer_optimizer_lr\n",
    "last_layer_optimizer_specs = [{'params': ppnet.last_layer.parameters(), 'lr': last_layer_optimizer_lr}]\n",
    "last_layer_optimizer = torch.optim.Adam(last_layer_optimizer_specs)\n",
    "\n",
    "# weighting of different training losses\n",
    "from settings import coefs\n",
    "\n",
    "# number of training epochs, number of warm epochs, push start epoch, push epochs\n",
    "from settings import num_train_epochs, num_warm_epochs, push_start, push_epochs\n",
    "\n",
    "# train the model\n",
    "log('start training')\n",
    "import copy\n",
    "for epoch in range(num_train_epochs):\n",
    "    log('epoch: \\t{0}'.format(epoch))\n",
    "\n",
    "    if epoch < num_warm_epochs:\n",
    "        tnt.warm_only(model=ppnet_multi, log=log)\n",
    "        _ = tnt.train(model=ppnet_multi, dataloader=train_loader, optimizer=warm_optimizer,\n",
    "                      class_specific=class_specific, coefs=coefs, log=log)\n",
    "    else:\n",
    "        tnt.joint(model=ppnet_multi, log=log)\n",
    "        joint_lr_scheduler.step()\n",
    "        _ = tnt.train(model=ppnet_multi, dataloader=train_loader, optimizer=joint_optimizer,\n",
    "                      class_specific=class_specific, coefs=coefs, log=log)\n",
    "\n",
    "    accu = tnt.test(model=ppnet_multi, dataloader=train_loader,  # CHANGE TEST_LOADER TO TRAIN_LOADER\n",
    "                    class_specific=class_specific, log=log)\n",
    "    save.save_model_w_condition(model=ppnet, model_dir=model_dir, model_name=str(epoch) + 'nopush', accu=accu,\n",
    "                                target_accu=0.70, log=log)\n",
    "\n",
    "    if epoch >= push_start and epoch in push_epochs:\n",
    "        push.push_prototypes(\n",
    "            train_loader, # pytorch dataloader (must be unnormalized in [0,1])   # CHANGE TRAIN_PUSH_LOADER TO TRAIN_LOADER\n",
    "            prototype_network_parallel=ppnet_multi, # pytorch network with prototype_vectors\n",
    "            class_specific=class_specific,\n",
    "            preprocess_input_function=preprocess_input_function, # normalize if needed\n",
    "            prototype_layer_stride=1,\n",
    "            root_dir_for_saving_prototypes=img_dir, # if not None, prototypes will be saved here\n",
    "            epoch_number=epoch, # if not provided, prototypes saved previously will be overwritten\n",
    "            prototype_img_filename_prefix=prototype_img_filename_prefix,\n",
    "            prototype_self_act_filename_prefix=prototype_self_act_filename_prefix,\n",
    "            proto_bound_boxes_filename_prefix=proto_bound_boxes_filename_prefix,\n",
    "            save_prototype_class_identity=True,\n",
    "            log=log)\n",
    "        accu = tnt.test(model=ppnet_multi, dataloader=train_loader,  # CHANGE TEST_LOADER TO TRAIN_LOADER\n",
    "                        class_specific=class_specific, log=log)\n",
    "        save.save_model_w_condition(model=ppnet, model_dir=model_dir, model_name=str(epoch) + 'push', accu=accu,\n",
    "                                    target_accu=0.70, log=log)\n",
    " \n",
    "        if prototype_activation_function != 'linear':\n",
    "            tnt.last_only(model=ppnet_multi, log=log)\n",
    "            for i in range(20):\n",
    "                log('iteration: \\t{0}'.format(i))\n",
    "                _ = tnt.train(model=ppnet_multi, dataloader=train_loader, optimizer=last_layer_optimizer,\n",
    "                              class_specific=class_specific, coefs=coefs, log=log)\n",
    "                accu = tnt.test(model=ppnet_multi, dataloader=train_loader, # CHANGE TEST_LOADER TO TRAIN_LOADER\n",
    "                                class_specific=class_specific, log=log)\n",
    "                save.save_model_w_condition(model=ppnet, model_dir=model_dir, model_name=str(epoch) + '_' + str(i) + 'push', accu=accu,\n",
    "                                            target_accu=0.70, log=log)\n",
    "   \n",
    "logclose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a92179a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test message\n"
     ]
    }
   ],
   "source": [
    "def log_to_file_and_console(message, logfile='results.txt'):\n",
    "    print(message)\n",
    "    with open(logfile, 'a') as f:\n",
    "        f.write(message + '\\n')\n",
    "\n",
    "log_to_file_and_console(\"Test message\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a04063-cd2d-47a1-9d54-fef786499d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating df for 5 class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "571cf093-1c3c-4fb1-ac83-e6c707c1dea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "scp_statements_path = '../../../data/padmalab_external/special_project/physionet.org/files/ptb-xl/1.0.3/scp_statements.csv'\n",
    "database_path = '../../../data/padmalab_external/special_project/physionet.org/files/ptb-xl/1.0.3/ptbxl_database.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d7a81af-2954-4db6-ba70-0e3c126c0a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scp statements file\n",
    "df = pd.read_csv(scp_statements_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd04ce72-5221-46ab-98d2-d11ab8a33876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>diagnostic</th>\n",
       "      <th>form</th>\n",
       "      <th>rhythm</th>\n",
       "      <th>diagnostic_class</th>\n",
       "      <th>diagnostic_subclass</th>\n",
       "      <th>Statement Category</th>\n",
       "      <th>SCP-ECG Statement Description</th>\n",
       "      <th>AHA code</th>\n",
       "      <th>aECG REFID</th>\n",
       "      <th>CDISC Code</th>\n",
       "      <th>DICOM Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NDT</td>\n",
       "      <td>non-diagnostic T abnormalities</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STTC</td>\n",
       "      <td>STTC</td>\n",
       "      <td>other ST-T descriptive statements</td>\n",
       "      <td>non-diagnostic T abnormalities</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NST_</td>\n",
       "      <td>non-specific ST changes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STTC</td>\n",
       "      <td>NST_</td>\n",
       "      <td>Basic roots for coding ST-T changes and abnorm...</td>\n",
       "      <td>non-specific ST changes</td>\n",
       "      <td>145.0</td>\n",
       "      <td>MDC_ECG_RHY_STHILOST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DIG</td>\n",
       "      <td>digitalis-effect</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STTC</td>\n",
       "      <td>STTC</td>\n",
       "      <td>other ST-T descriptive statements</td>\n",
       "      <td>suggests digitalis-effect</td>\n",
       "      <td>205.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LNGQT</td>\n",
       "      <td>long QT-interval</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STTC</td>\n",
       "      <td>STTC</td>\n",
       "      <td>other ST-T descriptive statements</td>\n",
       "      <td>long QT-interval</td>\n",
       "      <td>148.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NORM</td>\n",
       "      <td>normal ECG</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORM</td>\n",
       "      <td>NORM</td>\n",
       "      <td>Normal/abnormal</td>\n",
       "      <td>normal ECG</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F-000B7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0                     description  diagnostic  form  rhythm  \\\n",
       "0        NDT  non-diagnostic T abnormalities         1.0   1.0     NaN   \n",
       "1       NST_         non-specific ST changes         1.0   1.0     NaN   \n",
       "2        DIG                digitalis-effect         1.0   1.0     NaN   \n",
       "3      LNGQT                long QT-interval         1.0   1.0     NaN   \n",
       "4       NORM                      normal ECG         1.0   NaN     NaN   \n",
       "\n",
       "  diagnostic_class diagnostic_subclass  \\\n",
       "0             STTC                STTC   \n",
       "1             STTC                NST_   \n",
       "2             STTC                STTC   \n",
       "3             STTC                STTC   \n",
       "4             NORM                NORM   \n",
       "\n",
       "                                  Statement Category  \\\n",
       "0                  other ST-T descriptive statements   \n",
       "1  Basic roots for coding ST-T changes and abnorm...   \n",
       "2                  other ST-T descriptive statements   \n",
       "3                  other ST-T descriptive statements   \n",
       "4                                    Normal/abnormal   \n",
       "\n",
       "    SCP-ECG Statement Description  AHA code            aECG REFID CDISC Code  \\\n",
       "0  non-diagnostic T abnormalities       NaN                   NaN        NaN   \n",
       "1         non-specific ST changes     145.0  MDC_ECG_RHY_STHILOST        NaN   \n",
       "2       suggests digitalis-effect     205.0                   NaN        NaN   \n",
       "3                long QT-interval     148.0                   NaN        NaN   \n",
       "4                      normal ECG       1.0                   NaN        NaN   \n",
       "\n",
       "  DICOM Code  \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "2        NaN  \n",
       "3        NaN  \n",
       "4    F-000B7  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cbe5f06-0359-4dc0-bc30-4a6d039f71b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['STTC', 'NORM', 'MI', 'HYP', 'CD', nan], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['diagnostic_class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f366584-a312-4045-89f9-af8d853948df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ecg_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>nurse</th>\n",
       "      <th>site</th>\n",
       "      <th>device</th>\n",
       "      <th>recording_date</th>\n",
       "      <th>...</th>\n",
       "      <th>validated_by_human</th>\n",
       "      <th>baseline_drift</th>\n",
       "      <th>static_noise</th>\n",
       "      <th>burst_noise</th>\n",
       "      <th>electrodes_problems</th>\n",
       "      <th>extra_beats</th>\n",
       "      <th>pacemaker</th>\n",
       "      <th>strat_fold</th>\n",
       "      <th>filename_lr</th>\n",
       "      <th>filename_hr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15709.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1984-11-09 09:17:34</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>, I-V1,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>records100/00000/00001_lr</td>\n",
       "      <td>records500/00000/00001_hr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>13243.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1984-11-14 12:55:37</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>records100/00000/00002_lr</td>\n",
       "      <td>records500/00000/00002_hr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>20372.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1984-11-15 12:49:10</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>records100/00000/00003_lr</td>\n",
       "      <td>records500/00000/00003_hr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>17014.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1984-11-15 13:44:57</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>, II,III,AVF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>records100/00000/00004_lr</td>\n",
       "      <td>records500/00000/00004_hr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>17448.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1984-11-17 10:43:15</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>, III,AVR,AVF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>records100/00000/00005_lr</td>\n",
       "      <td>records500/00000/00005_hr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ecg_id  patient_id   age  sex  height  weight  nurse  site     device  \\\n",
       "0       1     15709.0  56.0    1     NaN    63.0    2.0   0.0  CS-12   E   \n",
       "1       2     13243.0  19.0    0     NaN    70.0    2.0   0.0  CS-12   E   \n",
       "2       3     20372.0  37.0    1     NaN    69.0    2.0   0.0  CS-12   E   \n",
       "3       4     17014.0  24.0    0     NaN    82.0    2.0   0.0  CS-12   E   \n",
       "4       5     17448.0  19.0    1     NaN    70.0    2.0   0.0  CS-12   E   \n",
       "\n",
       "        recording_date  ... validated_by_human  baseline_drift static_noise  \\\n",
       "0  1984-11-09 09:17:34  ...               True             NaN    , I-V1,     \n",
       "1  1984-11-14 12:55:37  ...               True             NaN          NaN   \n",
       "2  1984-11-15 12:49:10  ...               True             NaN          NaN   \n",
       "3  1984-11-15 13:44:57  ...               True    , II,III,AVF          NaN   \n",
       "4  1984-11-17 10:43:15  ...               True   , III,AVR,AVF          NaN   \n",
       "\n",
       "  burst_noise electrodes_problems  extra_beats  pacemaker  strat_fold  \\\n",
       "0         NaN                 NaN          NaN        NaN           3   \n",
       "1         NaN                 NaN          NaN        NaN           2   \n",
       "2         NaN                 NaN          NaN        NaN           5   \n",
       "3         NaN                 NaN          NaN        NaN           3   \n",
       "4         NaN                 NaN          NaN        NaN           4   \n",
       "\n",
       "                 filename_lr                filename_hr  \n",
       "0  records100/00000/00001_lr  records500/00000/00001_hr  \n",
       "1  records100/00000/00002_lr  records500/00000/00002_hr  \n",
       "2  records100/00000/00003_lr  records500/00000/00003_hr  \n",
       "3  records100/00000/00004_lr  records500/00000/00004_hr  \n",
       "4  records100/00000/00005_lr  records500/00000/00005_hr  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# database\n",
    "df2 = pd.read_csv(database_path)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74e5acbf-d5c4-4efa-a65f-ccf47c79bd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21799\n",
      "16056\n"
     ]
    }
   ],
   "source": [
    "print(len(df2))\n",
    "print(len(df2.loc[df2['validated_by_human'] == True]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67c27ba8-0be3-4800-85af-31069a8d64d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and convert annotation data\n",
    "Y = pd.read_csv(database_path, index_col='ecg_id')\n",
    "Y.scp_codes = Y.scp_codes.apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b1433e2-d716-4a13-a0d2-8e7a3589fbe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ecg_id\n",
       "1                 {'NORM': 100.0, 'LVOLT': 0.0, 'SR': 0.0}\n",
       "2                             {'NORM': 80.0, 'SBRAD': 0.0}\n",
       "3                               {'NORM': 100.0, 'SR': 0.0}\n",
       "4                               {'NORM': 100.0, 'SR': 0.0}\n",
       "5                               {'NORM': 100.0, 'SR': 0.0}\n",
       "                               ...                        \n",
       "21833    {'NDT': 100.0, 'PVC': 100.0, 'VCLVH': 0.0, 'ST...\n",
       "21834             {'NORM': 100.0, 'ABQRS': 0.0, 'SR': 0.0}\n",
       "21835                           {'ISCAS': 50.0, 'SR': 0.0}\n",
       "21836                           {'NORM': 100.0, 'SR': 0.0}\n",
       "21837                           {'NORM': 100.0, 'SR': 0.0}\n",
       "Name: scp_codes, Length: 21799, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.scp_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9284ebc3-6a4f-4dbd-97d0-3b6d93121ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load scp_statements.csv for diagnostic aggregation\n",
    "agg_df = pd.read_csv(scp_statements_path, index_col=0)\n",
    "agg_df = agg_df[agg_df.diagnostic == 1]\n",
    "\n",
    "def aggregate_diagnostic(y_dic):\n",
    "    tmp = []\n",
    "    for key in y_dic.keys():\n",
    "        if key in agg_df.index:\n",
    "            tmp.append(agg_df.loc[key].diagnostic_class)\n",
    "    return list(set(tmp))\n",
    "\n",
    "# Apply diagnostic superclass\n",
    "Y['diagnostic_superclass'] = Y.scp_codes.apply(aggregate_diagnostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6910fff-10f6-4fbd-835c-696295ba96f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>nurse</th>\n",
       "      <th>site</th>\n",
       "      <th>device</th>\n",
       "      <th>recording_date</th>\n",
       "      <th>report</th>\n",
       "      <th>...</th>\n",
       "      <th>baseline_drift</th>\n",
       "      <th>static_noise</th>\n",
       "      <th>burst_noise</th>\n",
       "      <th>electrodes_problems</th>\n",
       "      <th>extra_beats</th>\n",
       "      <th>pacemaker</th>\n",
       "      <th>strat_fold</th>\n",
       "      <th>filename_lr</th>\n",
       "      <th>filename_hr</th>\n",
       "      <th>diagnostic_superclass</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecg_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15709.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1984-11-09 09:17:34</td>\n",
       "      <td>sinusrhythmus periphere niederspannung</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>, I-V1,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>records100/00000/00001_lr</td>\n",
       "      <td>records500/00000/00001_hr</td>\n",
       "      <td>[NORM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13243.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1984-11-14 12:55:37</td>\n",
       "      <td>sinusbradykardie sonst normales ekg</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>records100/00000/00002_lr</td>\n",
       "      <td>records500/00000/00002_hr</td>\n",
       "      <td>[NORM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20372.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1984-11-15 12:49:10</td>\n",
       "      <td>sinusrhythmus normales ekg</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>records100/00000/00003_lr</td>\n",
       "      <td>records500/00000/00003_hr</td>\n",
       "      <td>[NORM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17014.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1984-11-15 13:44:57</td>\n",
       "      <td>sinusrhythmus normales ekg</td>\n",
       "      <td>...</td>\n",
       "      <td>, II,III,AVF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>records100/00000/00004_lr</td>\n",
       "      <td>records500/00000/00004_hr</td>\n",
       "      <td>[NORM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17448.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1984-11-17 10:43:15</td>\n",
       "      <td>sinusrhythmus normales ekg</td>\n",
       "      <td>...</td>\n",
       "      <td>, III,AVR,AVF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>records100/00000/00005_lr</td>\n",
       "      <td>records500/00000/00005_hr</td>\n",
       "      <td>[NORM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19005.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1984-11-28 13:32:13</td>\n",
       "      <td>sinusrhythmus normales ekg</td>\n",
       "      <td>...</td>\n",
       "      <td>, V1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>records100/00000/00006_lr</td>\n",
       "      <td>records500/00000/00006_hr</td>\n",
       "      <td>[NORM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16193.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1984-11-28 13:32:22</td>\n",
       "      <td>sinusrhythmus linkstyp t abnormal, wahrscheinl...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>records100/00000/00007_lr</td>\n",
       "      <td>records500/00000/00007_hr</td>\n",
       "      <td>[NORM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11275.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1984-12-01 14:49:52</td>\n",
       "      <td>sinusrhythmus linkstyp qrs(t) abnormal    infe...</td>\n",
       "      <td>...</td>\n",
       "      <td>, II,AVF</td>\n",
       "      <td>, I-AVF,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>records100/00000/00008_lr</td>\n",
       "      <td>records500/00000/00008_hr</td>\n",
       "      <td>[MI]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18792.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1984-12-08 09:44:43</td>\n",
       "      <td>sinusrhythmus normales ekg</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>, I-AVR,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>records100/00000/00009_lr</td>\n",
       "      <td>records500/00000/00009_hr</td>\n",
       "      <td>[NORM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9456.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1984-12-12 14:12:46</td>\n",
       "      <td>sinusrhythmus normales ekg</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>records100/00000/00010_lr</td>\n",
       "      <td>records500/00000/00010_hr</td>\n",
       "      <td>[NORM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11243.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1984-12-16 14:20:39</td>\n",
       "      <td>sinus arrhythmie sonst normales ekg</td>\n",
       "      <td>...</td>\n",
       "      <td>, II-AVL,AVF</td>\n",
       "      <td>, I-AVL,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>records100/00000/00011_lr</td>\n",
       "      <td>records500/00000/00011_hr</td>\n",
       "      <td>[NORM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11031.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1984-12-21 08:02:26</td>\n",
       "      <td>sinusbradykardie sonst normales ekg</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>records100/00000/00012_lr</td>\n",
       "      <td>records500/00000/00012_hr</td>\n",
       "      <td>[NORM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>19953.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1985-01-05 12:13:05</td>\n",
       "      <td>sinusrhythmus normales ekg</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>, I-AVR,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>records100/00000/00013_lr</td>\n",
       "      <td>records500/00000/00013_hr</td>\n",
       "      <td>[NORM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>12925.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1985-01-10 11:45:19</td>\n",
       "      <td>sinusrhythmus normales ekg</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>records100/00000/00014_lr</td>\n",
       "      <td>records500/00000/00014_hr</td>\n",
       "      <td>[NORM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13375.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1985-01-12 10:39:41</td>\n",
       "      <td>sinus arrhythmie sonst normales ekg</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>, I-AVR,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1ES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>records100/00000/00015_lr</td>\n",
       "      <td>records500/00000/00015_hr</td>\n",
       "      <td>[NORM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10999.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1985-01-16 08:27:38</td>\n",
       "      <td>sinusrhythmus normales ekg</td>\n",
       "      <td>...</td>\n",
       "      <td>, V1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>records100/00000/00016_lr</td>\n",
       "      <td>records500/00000/00016_hr</td>\n",
       "      <td>[NORM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>13619.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1985-01-20 14:25:25</td>\n",
       "      <td>vorhof:hf  280 tachykardes vorhofflimmern uebe...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>, alles,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>records100/00000/00017_lr</td>\n",
       "      <td>records500/00000/00017_hr</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>13619.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1985-01-20 15:17:24</td>\n",
       "      <td>vorhofflattern 2:1 Ãœberleitung,jetzt nach isop...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>, alles,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>records100/00000/00018_lr</td>\n",
       "      <td>records500/00000/00018_hr</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>11116.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1985-01-23 11:23:00</td>\n",
       "      <td>sinusrhythmus p-verbreiterung</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>records100/00000/00019_lr</td>\n",
       "      <td>records500/00000/00019_hr</td>\n",
       "      <td>[NORM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>13619.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1985-01-23 12:55:32</td>\n",
       "      <td>supraventrikulÃ„re ersatzsystole(n) interponier...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>records100/00000/00020_lr</td>\n",
       "      <td>records500/00000/00020_hr</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        patient_id   age  sex  height  weight  nurse  site     device  \\\n",
       "ecg_id                                                                  \n",
       "1          15709.0  56.0    1     NaN    63.0    2.0   0.0  CS-12   E   \n",
       "2          13243.0  19.0    0     NaN    70.0    2.0   0.0  CS-12   E   \n",
       "3          20372.0  37.0    1     NaN    69.0    2.0   0.0  CS-12   E   \n",
       "4          17014.0  24.0    0     NaN    82.0    2.0   0.0  CS-12   E   \n",
       "5          17448.0  19.0    1     NaN    70.0    2.0   0.0  CS-12   E   \n",
       "6          19005.0  18.0    1     NaN    58.0    2.0   0.0  CS-12   E   \n",
       "7          16193.0  54.0    0     NaN    83.0    2.0   0.0  CS-12   E   \n",
       "8          11275.0  48.0    0     NaN    95.0    2.0   0.0  CS-12   E   \n",
       "9          18792.0  55.0    0     NaN    70.0    2.0   0.0  CS-12   E   \n",
       "10          9456.0  22.0    1     NaN    56.0    2.0   0.0  CS-12   E   \n",
       "11         11243.0  20.0    1     NaN    57.0    2.0   0.0  CS-12   E   \n",
       "12         11031.0  43.0    1     NaN    44.0    2.0   0.0  CS-12   E   \n",
       "13         19953.0  58.0    1     NaN    54.0    2.0   0.0  CS-12   E   \n",
       "14         12925.0  19.0    1     NaN    58.0    2.0   0.0  CS-12   E   \n",
       "15         13375.0  17.0    1     NaN    67.0    2.0   0.0  CS-12   E   \n",
       "16         10999.0  49.0    0     NaN    79.0    2.0   0.0  CS-12   E   \n",
       "17         13619.0  56.0    0     NaN     NaN    2.0   0.0  CS-12   E   \n",
       "18         13619.0  56.0    0     NaN     NaN    2.0   0.0  CS-12   E   \n",
       "19         11116.0  20.0    0     NaN    85.0    2.0   0.0  CS-12   E   \n",
       "20         13619.0  56.0    0     NaN     NaN    2.0   0.0  CS-12   E   \n",
       "\n",
       "             recording_date  \\\n",
       "ecg_id                        \n",
       "1       1984-11-09 09:17:34   \n",
       "2       1984-11-14 12:55:37   \n",
       "3       1984-11-15 12:49:10   \n",
       "4       1984-11-15 13:44:57   \n",
       "5       1984-11-17 10:43:15   \n",
       "6       1984-11-28 13:32:13   \n",
       "7       1984-11-28 13:32:22   \n",
       "8       1984-12-01 14:49:52   \n",
       "9       1984-12-08 09:44:43   \n",
       "10      1984-12-12 14:12:46   \n",
       "11      1984-12-16 14:20:39   \n",
       "12      1984-12-21 08:02:26   \n",
       "13      1985-01-05 12:13:05   \n",
       "14      1985-01-10 11:45:19   \n",
       "15      1985-01-12 10:39:41   \n",
       "16      1985-01-16 08:27:38   \n",
       "17      1985-01-20 14:25:25   \n",
       "18      1985-01-20 15:17:24   \n",
       "19      1985-01-23 11:23:00   \n",
       "20      1985-01-23 12:55:32   \n",
       "\n",
       "                                                   report  ...  \\\n",
       "ecg_id                                                     ...   \n",
       "1                  sinusrhythmus periphere niederspannung  ...   \n",
       "2                     sinusbradykardie sonst normales ekg  ...   \n",
       "3                              sinusrhythmus normales ekg  ...   \n",
       "4                              sinusrhythmus normales ekg  ...   \n",
       "5                              sinusrhythmus normales ekg  ...   \n",
       "6                              sinusrhythmus normales ekg  ...   \n",
       "7       sinusrhythmus linkstyp t abnormal, wahrscheinl...  ...   \n",
       "8       sinusrhythmus linkstyp qrs(t) abnormal    infe...  ...   \n",
       "9                              sinusrhythmus normales ekg  ...   \n",
       "10                             sinusrhythmus normales ekg  ...   \n",
       "11                    sinus arrhythmie sonst normales ekg  ...   \n",
       "12                    sinusbradykardie sonst normales ekg  ...   \n",
       "13                             sinusrhythmus normales ekg  ...   \n",
       "14                             sinusrhythmus normales ekg  ...   \n",
       "15                    sinus arrhythmie sonst normales ekg  ...   \n",
       "16                             sinusrhythmus normales ekg  ...   \n",
       "17      vorhof:hf  280 tachykardes vorhofflimmern uebe...  ...   \n",
       "18      vorhofflattern 2:1 Ãœberleitung,jetzt nach isop...  ...   \n",
       "19                          sinusrhythmus p-verbreiterung  ...   \n",
       "20      supraventrikulÃ„re ersatzsystole(n) interponier...  ...   \n",
       "\n",
       "        baseline_drift static_noise burst_noise electrodes_problems  \\\n",
       "ecg_id                                                                \n",
       "1                  NaN    , I-V1,           NaN                 NaN   \n",
       "2                  NaN          NaN         NaN                 NaN   \n",
       "3                  NaN          NaN         NaN                 NaN   \n",
       "4         , II,III,AVF          NaN         NaN                 NaN   \n",
       "5        , III,AVR,AVF          NaN         NaN                 NaN   \n",
       "6                 , V1          NaN         NaN                 NaN   \n",
       "7                  NaN          NaN         NaN                 NaN   \n",
       "8             , II,AVF   , I-AVF,           NaN                 NaN   \n",
       "9                  NaN   , I-AVR,           NaN                 NaN   \n",
       "10                 NaN          NaN         NaN                 NaN   \n",
       "11        , II-AVL,AVF   , I-AVL,           NaN                 NaN   \n",
       "12                 NaN          NaN         NaN                 NaN   \n",
       "13                 NaN   , I-AVR,           NaN                 NaN   \n",
       "14                 NaN          NaN         NaN                 NaN   \n",
       "15                 NaN   , I-AVR,           NaN                 NaN   \n",
       "16                , V1          NaN         NaN                 NaN   \n",
       "17                 NaN   , alles,           NaN                 NaN   \n",
       "18                 NaN   , alles,           NaN                 NaN   \n",
       "19                 NaN          NaN         NaN                 NaN   \n",
       "20                 NaN          NaN         NaN                 NaN   \n",
       "\n",
       "        extra_beats  pacemaker  strat_fold                filename_lr  \\\n",
       "ecg_id                                                                  \n",
       "1               NaN        NaN           3  records100/00000/00001_lr   \n",
       "2               NaN        NaN           2  records100/00000/00002_lr   \n",
       "3               NaN        NaN           5  records100/00000/00003_lr   \n",
       "4               NaN        NaN           3  records100/00000/00004_lr   \n",
       "5               NaN        NaN           4  records100/00000/00005_lr   \n",
       "6               NaN        NaN           4  records100/00000/00006_lr   \n",
       "7               NaN        NaN           7  records100/00000/00007_lr   \n",
       "8               NaN        NaN           9  records100/00000/00008_lr   \n",
       "9               NaN        NaN          10  records100/00000/00009_lr   \n",
       "10              NaN        NaN           9  records100/00000/00010_lr   \n",
       "11              NaN        NaN           5  records100/00000/00011_lr   \n",
       "12              NaN        NaN           8  records100/00000/00012_lr   \n",
       "13              NaN        NaN           2  records100/00000/00013_lr   \n",
       "14              NaN        NaN           7  records100/00000/00014_lr   \n",
       "15              1ES        NaN           3  records100/00000/00015_lr   \n",
       "16              NaN        NaN           6  records100/00000/00016_lr   \n",
       "17              NaN        NaN           9  records100/00000/00017_lr   \n",
       "18              NaN        NaN           9  records100/00000/00018_lr   \n",
       "19              NaN        NaN           7  records100/00000/00019_lr   \n",
       "20              VES        NaN           9  records100/00000/00020_lr   \n",
       "\n",
       "                      filename_hr diagnostic_superclass  \n",
       "ecg_id                                                   \n",
       "1       records500/00000/00001_hr                [NORM]  \n",
       "2       records500/00000/00002_hr                [NORM]  \n",
       "3       records500/00000/00003_hr                [NORM]  \n",
       "4       records500/00000/00004_hr                [NORM]  \n",
       "5       records500/00000/00005_hr                [NORM]  \n",
       "6       records500/00000/00006_hr                [NORM]  \n",
       "7       records500/00000/00007_hr                [NORM]  \n",
       "8       records500/00000/00008_hr                  [MI]  \n",
       "9       records500/00000/00009_hr                [NORM]  \n",
       "10      records500/00000/00010_hr                [NORM]  \n",
       "11      records500/00000/00011_hr                [NORM]  \n",
       "12      records500/00000/00012_hr                [NORM]  \n",
       "13      records500/00000/00013_hr                [NORM]  \n",
       "14      records500/00000/00014_hr                [NORM]  \n",
       "15      records500/00000/00015_hr                [NORM]  \n",
       "16      records500/00000/00016_hr                [NORM]  \n",
       "17      records500/00000/00017_hr                    []  \n",
       "18      records500/00000/00018_hr                    []  \n",
       "19      records500/00000/00019_hr                [NORM]  \n",
       "20      records500/00000/00020_hr                    []  \n",
       "\n",
       "[20 rows x 28 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af4cb8bc-9218-4ba9-b802-42c3fb5388c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test\n",
    "test_fold = 10\n",
    "\n",
    "# Train\n",
    "y_train = Y[(Y.strat_fold != test_fold)].diagnostic_superclass\n",
    "# Test\n",
    "y_test = Y[Y.strat_fold == test_fold].diagnostic_superclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63a7da03-dd24-4e72-bc93-454e459347ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list(['CD']) list(['HYP']) list(['MI']) list(['NORM']) list(['STTC'])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14594"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter to get only elements with one class\n",
    "y_train_single_class = y_train[y_train.apply(lambda x: len(x) == 1)]\n",
    "\n",
    "# Get unique classes in the filtered elements\n",
    "unique_classes = np.unique(y_train_single_class)\n",
    "\n",
    "print(unique_classes)\n",
    "len(y_train_single_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33da5972-eba7-412d-82f7-67af4359350c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ecg_id\n",
       "1     [NORM]\n",
       "2     [NORM]\n",
       "3     [NORM]\n",
       "4     [NORM]\n",
       "5     [NORM]\n",
       "6     [NORM]\n",
       "7     [NORM]\n",
       "8       [MI]\n",
       "10    [NORM]\n",
       "11    [NORM]\n",
       "12    [NORM]\n",
       "13    [NORM]\n",
       "14    [NORM]\n",
       "15    [NORM]\n",
       "16    [NORM]\n",
       "19    [NORM]\n",
       "21    [NORM]\n",
       "22    [STTC]\n",
       "24    [NORM]\n",
       "25    [NORM]\n",
       "26    [STTC]\n",
       "27    [NORM]\n",
       "28    [STTC]\n",
       "29    [NORM]\n",
       "30     [HYP]\n",
       "31    [NORM]\n",
       "32      [CD]\n",
       "33    [NORM]\n",
       "35    [NORM]\n",
       "36    [NORM]\n",
       "Name: diagnostic_superclass, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_single_class[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04e0bae4-ddec-4224-b60c-f43b942d98c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integer Encoded Labels:  [3 3 3 3 3 3 3 2 3 3 3 3 3 3 3 3 3 4 3 3 4 3 4 3 1 3 0 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Flatten the list structure\n",
    "y_train_flat = y_train_single_class.apply(lambda x: x[0])\n",
    "\n",
    "# Initialize the label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the label encoder and transform the labels to integer encoded labels\n",
    "y_train_encoded = label_encoder.fit_transform(y_train_flat)\n",
    "\n",
    "print(\"Integer Encoded Labels: \", y_train_encoded[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1ce4316-16be-49a8-93f9-7447aceb121b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping:  {'CD': 0, 'HYP': 1, 'MI': 2, 'NORM': 3, 'STTC': 4}\n"
     ]
    }
   ],
   "source": [
    "# Print the mapping of integers to original labels\n",
    "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(\"Label Mapping: \", label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aaa66c1c-f475-46a7-abf1-98d152f16d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1650\n",
      "14594\n",
      "torch.Size([32, 3, 224, 224]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import ast\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "scp_statements_path = '../../../data/padmalab_external/special_project/physionet.org/files/ptb-xl/1.0.3/scp_statements.csv'\n",
    "database_path = '../../../data/padmalab_external/special_project/physionet.org/files/ptb-xl/1.0.3/ptbxl_database.csv'\n",
    "img_dir = \"../../../data/padmalab_external/special_project/physionet.org/files/ptb-xl/1.0.3/records100_ground_truth\"\n",
    "\n",
    "# Define transformations\n",
    "img_size = 224  # or whatever size you want\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "class ECGImageDataset(Dataset):\n",
    "    def __init__(self, scp_statements_df_path, ptb_xl_database_df_path, image_dir, transform=None, test=False):\n",
    "        self.scp_statements_df_path = scp_statements_df_path\n",
    "        self.ptb_xl_database_df_path = ptb_xl_database_df_path\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.ecg_labels, self.ecg_paths = self.get_ecg_paths_and_labels(test)\n",
    "        self.image_paths = self._get_image_paths()\n",
    "\n",
    "    def get_ecg_paths_and_labels(self, test):\n",
    "        # Load the database file\n",
    "        ptb_xl_database_df = pd.read_csv(self.ptb_xl_database_df_path, index_col='ecg_id')\n",
    "        ptb_xl_database_df.scp_codes = ptb_xl_database_df.scp_codes.apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "        # Load scp_statements.csv for diagnostic aggregation\n",
    "        agg_df = pd.read_csv(self.scp_statements_df_path, index_col=0)\n",
    "        agg_df = agg_df[agg_df.diagnostic == 1]\n",
    "\n",
    "        def aggregate_diagnostic(y_dic):\n",
    "            tmp = []\n",
    "            for key in y_dic.keys():\n",
    "                if key in agg_df.index:\n",
    "                    tmp.append(agg_df.loc[key].diagnostic_class)\n",
    "            return list(set(tmp))\n",
    "\n",
    "        # Apply diagnostic superclass\n",
    "        ptb_xl_database_df['diagnostic_superclass'] = ptb_xl_database_df.scp_codes.apply(aggregate_diagnostic)\n",
    "        Y = ptb_xl_database_df\n",
    "\n",
    "        # Split data into train and test\n",
    "        test_fold = 10\n",
    "        y_train = Y[Y.strat_fold != test_fold]\n",
    "        y_test = Y[Y.strat_fold == test_fold]\n",
    "\n",
    "        if test:\n",
    "            y = y_test\n",
    "        else:\n",
    "            y = y_train\n",
    "\n",
    "        y_file_names = y.filename_lr.apply(lambda x: x.split('/')[-1])\n",
    "\n",
    "        # Filter to get only elements with one class\n",
    "        y_single_class = y[y.diagnostic_superclass.apply(lambda x: len(x) == 1)]\n",
    "\n",
    "        # Flatten the list structure\n",
    "        y_single_class_flat = y_single_class.diagnostic_superclass.apply(lambda x: x[0])\n",
    "\n",
    "        # Initialize the label encoder\n",
    "        label_encoder = LabelEncoder()\n",
    "\n",
    "        # Fit the label encoder and transform the labels to integer encoded labels\n",
    "        y_encoded = label_encoder.fit_transform(y_single_class_flat)\n",
    "\n",
    "        return y_encoded, y_file_names.loc[y_single_class.index]\n",
    "\n",
    "    def _get_image_paths(self):\n",
    "        image_paths = []\n",
    "        for root, _, files in os.walk(self.image_dir):\n",
    "            for file in files:\n",
    "                if file.endswith('.png'):\n",
    "                    image_paths.append(os.path.join(root, file))\n",
    "        return image_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ecg_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.ecg_paths.iloc[idx] + '-0.png'\n",
    "        matching_paths = [path for path in self.image_paths if img_name in path]\n",
    "\n",
    "        if not matching_paths:\n",
    "            raise FileNotFoundError(f\"Image {img_name} not found in the dataset.\")\n",
    "\n",
    "        img_path = matching_paths[0]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.ecg_labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(label).long()\n",
    "\n",
    "# Initialize dataset and dataloader for testing\n",
    "test_dataset = ECGImageDataset(scp_statements_path, database_path, img_dir, transform=transform, test=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32)\n",
    "print(len(test_dataset))\n",
    "\n",
    "# Initialize dataset and dataloader for training\n",
    "train_dataset = ECGImageDataset(scp_statements_path, database_path, img_dir, transform=transform, test=False)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32)\n",
    "print(len(train_dataset))\n",
    "\n",
    "# Print the shapes of the examples and labels from the train dataloader\n",
    "for examples, labels in train_dataloader:\n",
    "    print(examples.shape, labels.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8201882a-4ec5-4a85-8b90-0dfab21f1293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5a1a5521-8a69-4cdb-88b8-b25dcbeb90fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CODE TO CREATE LABELS FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "798dd4fa-88f5-49e6-913a-945aa781d70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "img_dir = \"../../../data/padmalab_external/special_project/physionet.org/files/ptb-xl/1.0.3/records100_ground_truth\"\n",
    "\n",
    "image_paths = []\n",
    "for root, _, files in os.walk(img_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.png'):\n",
    "            image_paths.append(os.path.join(root, file))\n",
    "# image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "095bf998-de80-4eb2-b4c7-c408aaa53745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping:  {'CD': 0, 'HYP': 1, 'MI': 2, 'NORM': 3, 'STTC': 4}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import ast\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "test = False\n",
    "# Load the database file\n",
    "ptb_xl_database_df = pd.read_csv(database_path, index_col='ecg_id')\n",
    "ptb_xl_database_df.scp_codes = ptb_xl_database_df.scp_codes.apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# Load scp_statements.csv for diagnostic aggregation\n",
    "agg_df = pd.read_csv(scp_statements_path, index_col=0)\n",
    "agg_df = agg_df[agg_df.diagnostic == 1]\n",
    "\n",
    "def aggregate_diagnostic(y_dic):\n",
    "    tmp = []\n",
    "    for key in y_dic.keys():\n",
    "        if key in agg_df.index:\n",
    "            tmp.append(agg_df.loc[key].diagnostic_class)\n",
    "    return list(set(tmp))\n",
    "\n",
    "# Apply diagnostic superclass\n",
    "ptb_xl_database_df['diagnostic_superclass'] = ptb_xl_database_df.scp_codes.apply(aggregate_diagnostic)\n",
    "Y = ptb_xl_database_df\n",
    "\n",
    "# Split data into train and test\n",
    "test_fold = 10\n",
    "y_train = Y[Y.strat_fold != test_fold]\n",
    "y_test = Y[Y.strat_fold == test_fold]\n",
    "\n",
    "if test:\n",
    "    y = y_test\n",
    "else:\n",
    "    y = y_train\n",
    "y_file_names = y.filename_lr.apply(lambda x: x.split('/')[-1])\n",
    "\n",
    "# Filter to get only elements with one class\n",
    "y_single_class = y[y.diagnostic_superclass.apply(lambda x: len(x) == 1)]\n",
    "y_file_names = y_file_names[y.diagnostic_superclass.apply(lambda x: len(x) == 1)]\n",
    "\n",
    "# Flatten the list structure\n",
    "y_single_class_flat = y_single_class.diagnostic_superclass.apply(lambda x: x[0])\n",
    "\n",
    "# Initialize the label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the label encoder and transform the labels to integer encoded labels\n",
    "y_encoded = label_encoder.fit_transform(y_single_class_flat)\n",
    "\n",
    "# Print the mapping of integers to original labels\n",
    "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(\"Label Mapping: \", label_mapping)\n",
    "\n",
    "y_labels = y_encoded\n",
    "y_paths = y_file_names.loc[y_single_class.index]\n",
    "# Reset index \n",
    "y_paths.reset_index(drop=True, inplace=True)\n",
    "y_paths.index += 0  # Update index to start from 0\n",
    "y_paths.index.name = 'index'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "86ce9a9b-0c97-4f65-b6b2-c0a77a5a8bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14594"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a93b0087-f824-41eb-a6dc-d8f13d605ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14594"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dbac8c90-598c-4d58-a372-5e21a00c7dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Image Path  Label\n",
      "0  ../../../data/padmalab_external/special_projec...      3\n",
      "1  ../../../data/padmalab_external/special_projec...      3\n",
      "2  ../../../data/padmalab_external/special_projec...      3\n",
      "3  ../../../data/padmalab_external/special_projec...      3\n",
      "4  ../../../data/padmalab_external/special_projec...      3\n",
      "Total matches: 12158\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to store the matched paths and labels\n",
    "data = []\n",
    "\n",
    "# Iterate over y_paths and image_paths to find matches and create rows for the dataframe\n",
    "for i in range(len(y_paths)):\n",
    "    y_path = y_paths[i]\n",
    "    for j in range(len(image_paths)):\n",
    "        img_path = image_paths[j]\n",
    "        if y_path in img_path:\n",
    "            data.append([img_path, y_labels[i]])\n",
    "\n",
    "# Convert the list to a pandas DataFrame\n",
    "df = pd.DataFrame(data, columns=['Image Path', 'Label'])\n",
    "\n",
    "# Print the first few rows of the DataFrame to verify\n",
    "print(df.head())\n",
    "print(f\"Total matches: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c82a60f-d2e5-4bd2-b5dc-760180de4634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell only for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a3821fef-d542-45be-af1c-8eaaf2eaaa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test-100HZ-files-and-labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ad655ec7-edcc-4116-8040-0d17c2e64324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the following 4 cells only for train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "63de0c6b-352d-49dd-81a6-8f799965515c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains\n",
      "1\n",
      "contains\n",
      "11506\n"
     ]
    }
   ],
   "source": [
    "for i in range(12158):\n",
    "    if 'checkpoint' in df.iloc[i][\"Image Path\"]:\n",
    "        print(\"contains\")\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "979ae519-f95a-4b24-b3ce-883fb1d796cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df = df.drop([1, 11506])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c767fdaa-1c2a-47bb-aed6-b117f67662b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12156"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(updated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3aaf9916-a4f6-4699-8251-fed8c01b9681",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df.to_csv('train-100HZ-files-and-labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "563e4a2d-7d13-4816-ace3-9d24501d2f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Path</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../../../data/padmalab_external/special_projec...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../../../data/padmalab_external/special_projec...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../../../data/padmalab_external/special_projec...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../../../data/padmalab_external/special_projec...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../../../data/padmalab_external/special_projec...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Image Path  Label\n",
       "0  ../../../data/padmalab_external/special_projec...      3\n",
       "1  ../../../data/padmalab_external/special_projec...      3\n",
       "2  ../../../data/padmalab_external/special_projec...      3\n",
       "3  ../../../data/padmalab_external/special_projec...      3\n",
       "4  ../../../data/padmalab_external/special_projec...      3"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_test = pd.read_csv('train-100HZ-files-and-labels.csv')\n",
    "load_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fe36c6-5e8c-4f51-8a27-77dbc7b66308",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 14592\n",
    "img_name = y_paths.iloc[idx] + '-0.png'\n",
    "print(img_name)\n",
    "matching_paths = [path for path in image_paths if img_name in path]\n",
    "if not matching_paths:\n",
    "    idx = 0\n",
    "while not matching_paths:\n",
    "    print(f'Here {idx}\\n')\n",
    "    img_name = y_paths.iloc[idx] + '-0.png'\n",
    "    matching_paths = [path for path in image_paths if img_name in path]\n",
    "    idx += 1\n",
    "    print(img_name)\n",
    "        \n",
    "matching_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7c9e5e-9fd3-4b0a-9cb7-0ef9a2ae75ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import ast\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "scp_statements_path = '../../../data/padmalab_external/special_project/physionet.org/files/ptb-xl/1.0.3/scp_statements.csv'\n",
    "database_path = '../../../data/padmalab_external/special_project/physionet.org/files/ptb-xl/1.0.3/ptbxl_database.csv'\n",
    "img_dir = \"../../../data/padmalab_external/special_project/physionet.org/files/ptb-xl/1.0.3/records100_ground_truth\"\n",
    "\n",
    "# Define transformations\n",
    "img_size = 224  # or whatever size you want\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "class ECGImageDataset(Dataset):\n",
    "    def __init__(self, scp_statements_df_path, ptb_xl_database_df_path, image_dir, transform=None, test=False):\n",
    "        self.scp_statements_df_path = scp_statements_df_path\n",
    "        self.ptb_xl_database_df_path = ptb_xl_database_df_path\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.ecg_labels, self.ecg_paths = self.get_ecg_paths_and_labels(test)\n",
    "        self.image_paths = self._get_image_paths()\n",
    "\n",
    "    def get_ecg_paths_and_labels(self, test):\n",
    "        # Load the database file\n",
    "        ptb_xl_database_df = pd.read_csv(self.ptb_xl_database_df_path, index_col='ecg_id')\n",
    "        ptb_xl_database_df.scp_codes = ptb_xl_database_df.scp_codes.apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "        # Load scp_statements.csv for diagnostic aggregation\n",
    "        agg_df = pd.read_csv(self.scp_statements_df_path, index_col=0)\n",
    "        agg_df = agg_df[agg_df.diagnostic == 1]\n",
    "\n",
    "        def aggregate_diagnostic(y_dic):\n",
    "            tmp = []\n",
    "            for key in y_dic.keys():\n",
    "                if key in agg_df.index:\n",
    "                    tmp.append(agg_df.loc[key].diagnostic_class)\n",
    "            return list(set(tmp))\n",
    "\n",
    "        # Apply diagnostic superclass\n",
    "        ptb_xl_database_df['diagnostic_superclass'] = ptb_xl_database_df.scp_codes.apply(aggregate_diagnostic)\n",
    "        Y = ptb_xl_database_df\n",
    "\n",
    "        # Split data into train and test\n",
    "        test_fold = 10\n",
    "        y_train = Y[Y.strat_fold != test_fold]\n",
    "        y_test = Y[Y.strat_fold == test_fold]\n",
    "\n",
    "        if test:\n",
    "            y = y_test\n",
    "        else:\n",
    "            y = y_train\n",
    "        y_file_names = y.filename_lr.apply(lambda x: x.split('/')[-1])\n",
    "\n",
    "        # Filter to get only elements with one class\n",
    "        y_single_class = y[y.diagnostic_superclass.apply(lambda x: len(x) == 1)]\n",
    "        y_file_names = y_file_names[y.diagnostic_superclass.apply(lambda x: len(x) == 1)]\n",
    "\n",
    "        # Flatten the list structure\n",
    "        y_single_class_flat = y_single_class.diagnostic_superclass.apply(lambda x: x[0])\n",
    "\n",
    "        # Initialize the label encoder\n",
    "        label_encoder = LabelEncoder()\n",
    "\n",
    "        # Fit the label encoder and transform the labels to integer encoded labels\n",
    "        y_encoded = label_encoder.fit_transform(y_single_class_flat)\n",
    "        # print(y_file_names.loc[y_single_class.index])\n",
    "\n",
    "        # Print the mapping of integers to original labels\n",
    "        label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "        print(\"Label Mapping: \", label_mapping)\n",
    "\n",
    "        y_labels = y_encoded\n",
    "        y_paths = y_file_names.loc[y_single_class.index]\n",
    "        \n",
    "        # Reset index \n",
    "        y_paths.reset_index(drop=True, inplace=True)\n",
    "        y_paths.index += 0  # Update index to start from 0\n",
    "        y_paths.index.name = 'index'\n",
    "\n",
    "        return y_labels, y_paths\n",
    "\n",
    "    def _get_image_paths(self):\n",
    "        image_paths = []\n",
    "        for root, _, files in os.walk(self.image_dir):\n",
    "            for file in files:\n",
    "                if file.endswith('.png'):\n",
    "                    image_paths.append(os.path.join(root, file))\n",
    "        return image_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ecg_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.ecg_paths.iloc[idx] + '-0.png'\n",
    "        matching_paths = [path for path in self.image_paths if img_name in path]\n",
    "\n",
    "        if not matching_paths:\n",
    "            idx = 0\n",
    "        while not matching_paths:\n",
    "            print(f'Here\\n')\n",
    "            img_name = self.ecg_paths.iloc[idx] + '-0.png'\n",
    "            matching_paths = [path for path in self.image_paths if img_name in path]\n",
    "            idx += 1\n",
    "\n",
    "        img_path = matching_paths[0]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.ecg_labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(label).long()\n",
    "\n",
    "# Initialize dataset and dataloader for training\n",
    "train_dataset = ECGImageDataset(scp_statements_path, database_path, img_dir, transform=transform, test=False)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=200)\n",
    "print(len(train_dataset))\n",
    "\n",
    "# Print the shapes of the examples and labels from the train dataloader\n",
    "from tqdm import tqdm\n",
    "for examples, labels in tqdm(train_dataloader):\n",
    "    print(examples.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3071b66-6da4-4efe-8431-60883c2ac54d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ecg_diagnosis_models)",
   "language": "python",
   "name": "ecg_diagnosis_models"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
